{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/evillag/TEC-ML-2022-1/blob/main/TP2/src_base/TP2_BayesianModel_MNIST_EVG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "fV91T7yxTRaL"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from PIL import Image\n",
        "import torchvision.transforms.functional as TF\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!wget https://github.com/evillag/TEC-ML-2022-1/raw/main/TP2/src_base/mnist_dataset.zip\n",
        "!unzip /content/mnist_dataset.zip"
      ],
      "metadata": {
        "id": "CD_niHaQTuJL"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "vXz83R23TRaM",
        "outputId": "5338430a-32b4-473f-a29a-8da3db5e6ecb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train dimensions  torch.Size([784, 600])\n",
            "train labels  600\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "\n",
        "def binarize_image(image_tensor):\n",
        "    image_tensor[image_tensor > 0.5] = 1\n",
        "    image_tensor[image_tensor <= 0.5] = 0\n",
        "    return image_tensor\n",
        "\n",
        "def load_dataset(path = \"mnist_dataset/train\"):\n",
        "    #Open up the dataset\n",
        "    dataset =  torchvision.datasets.ImageFolder(path)   \n",
        "    #print(dataset)\n",
        "    list_images = dataset.imgs\n",
        "    #print(list_images)\n",
        "    train_data_tensor  = None    \n",
        "    labels_training = []\n",
        "    first_tensor = True\n",
        "    #list_images_training =  set(data_labeled.train_ds.x.items)\n",
        "    #print(list_images)\n",
        "    for i in range(0, len(list_images)):\n",
        "        pair_path_label = list_images[i]        \n",
        "        image = Image.open(pair_path_label[0]) \n",
        "        x_tensor = TF.to_tensor(image).squeeze()\n",
        "        x_tensor_bin = binarize_image(x_tensor)\n",
        "\n",
        "        x_tensor_bin_plain = x_tensor_bin.view(x_tensor_bin.shape[0] * x_tensor_bin.shape[1], -1)        \n",
        "        #print(\"tensor \", x_tensor.shape)\n",
        "        #test dataset case        \n",
        "        #if(\"train\" in pair_path_label[0]):\n",
        "        labels_training += [pair_path_label[1]]\n",
        "        # print(pair_path_label)\n",
        "        if(first_tensor):\n",
        "            plt.figure()\n",
        "            plt.imshow(x_tensor_bin)\n",
        "            first_tensor = False\n",
        "            train_data_tensor = x_tensor_bin_plain\n",
        "        else:\n",
        "            train_data_tensor = torch.cat((train_data_tensor, x_tensor_bin_plain), 1)    \n",
        "    return (train_data_tensor, torch.tensor(labels_training))       \n",
        "\n",
        "\n",
        "(train_data_tensor, labels_training) = load_dataset(path = \"/content/mnist_dataset/train\")\n",
        "print(\"train dimensions \", train_data_tensor.shape)\n",
        "print(\"train labels \", len(labels_training))        \n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p_m_0_given_k shape torch.Size([10, 784])\n",
            "p_m_pix_val_given_k[0] size torch.Size([10, 784])\n",
            "p_m_pix_val_given_k[1] size torch.Size([10, 784])\n",
            "p_t_tensor \n",
            "\tclasses: torch.Size([10]).\n",
            "\tValues: tensor([0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
            "        0.1000])\n",
            "predicted_label  tensor(8)\n",
            "real label  tensor(8)\n",
            "Model accuracy  0.9166666666666666\n"
          ]
        }
      ],
      "source": [
        "# def _multiplication_test_model(input_torch, p_m_pix_val_given_k, p_t_tensor, \n",
        "#                                num_classes = 10):\n",
        "#     #assumes that the input comes in a row\n",
        "#     prob_naive_bayes = torch.zeros(num_classes, train_data_tensor.shape[0])\n",
        "#     scores_classes = torch.zeros(10)\n",
        "#     bias = 1.\n",
        "  \n",
        "#     for k in range(num_classes):\n",
        "#       idx_0 = (input_torch == 0.)\n",
        "#       idx_1 = (input_torch == 1.)\n",
        "#       prob_naive_bayes[k, idx_0] = (p_m_pix_val_given_k[0][k, idx_0] * p_t_tensor[k]) + bias\n",
        "#       prob_naive_bayes[k, idx_1] = (p_m_pix_val_given_k[1][k, idx_1] * p_t_tensor[k]) + bias\n",
        "#       scores_classes[k] = torch.prod(prob_naive_bayes[k,:], dtype=torch.double)\n",
        "\n",
        "#     values, indices = scores_classes.topk(1)\n",
        "#     predicted_label = indices[0]\n",
        "#     #print(scores_classes)\n",
        "#     #print(f'predicted_label: {indices[0]}. Score = {values[0]}')\n",
        "    \n",
        "#     return predicted_label, scores_classes\n",
        "\n",
        "def test_model(input_torch, p_m_pix_val_given_k, p_t_tensor, \n",
        "                               num_classes = 10):\n",
        "    # assumes that the input comes in a row\n",
        "    # Since the multiplicatory tends to give very small values, close to 0\n",
        "    # We are transforming the Naive Bayes by applying a log to it, so that:\n",
        "    # log(Mul(p(m|t)p(t))) = Sum(log(p(m|t)) + log(p(t)))\n",
        "\n",
        "    prob_naive_bayes = torch.zeros(num_classes, train_data_tensor.shape[0])\n",
        "    scores_classes = torch.zeros(10)\n",
        "      \n",
        "    for k in range(num_classes):\n",
        "      idx_0 = (input_torch == 0.) # indices of all pixels in 0\n",
        "      idx_1 = (input_torch == 1.) # indices of all pixels in 1\n",
        "\n",
        "      # probability of pixels = 0 given k:\n",
        "      prob_naive_bayes[k, idx_0] = torch.log(p_m_pix_val_given_k[0][k, idx_0]) + torch.log(p_t_tensor[k])\n",
        "\n",
        "      # probability of pixels = 1 given k:\n",
        "      prob_naive_bayes[k, idx_1] = torch.log(p_m_pix_val_given_k[1][k, idx_1]) + torch.log(p_t_tensor[k])\n",
        "\n",
        "      # calculate the class probability\n",
        "      scores_classes[k] = torch.sum(prob_naive_bayes[k,:], dtype=torch.double)\n",
        "\n",
        "    values, indices = scores_classes.topk(1)\n",
        "    predicted_label = indices[0]\n",
        "    #print(scores_classes)\n",
        "    #print(f'predicted_label: {indices[0]}. Score = {values[0]}')\n",
        "    \n",
        "    return predicted_label, scores_classes\n",
        "\n",
        "\n",
        "def test_model_batch(test_set, labels, p_m_pix_val_given_k, p_t_tensor):\n",
        "    correct = 0\n",
        "    \n",
        "    for i in range(labels.shape[0]):\n",
        "      predicted_label, _ = test_model(test_set[:,i], p_m_pix_val_given_k, \n",
        "                                      p_t_tensor)\n",
        "      correct += 1 if predicted_label == labels[i] else 0\n",
        "      # print(f'predicted = {predicted_label}. real = {labels[i]}')\n",
        "\n",
        "    accuracy = correct / labels.shape[0]\n",
        "    return accuracy\n",
        "\n",
        "\n",
        "def train_model(train_data_tensor, labels_training, num_classes = 10):\n",
        "  p_m_0_given_k = torch.zeros(num_classes, train_data_tensor.shape[0])\n",
        "  p_m_1_given_k = torch.ones(num_classes, train_data_tensor.shape[0])\n",
        "  \n",
        "  print(f'p_m_0_given_k shape {p_m_0_given_k.shape}')\n",
        "  \n",
        "  _, counts = torch.unique(labels_training, return_counts=True)\n",
        "  p_t_tensor = counts / len(labels_training)\n",
        "\n",
        "  for k in range(num_classes):\n",
        "    training_indices_of_class_k = (labels_training == k).nonzero().squeeze(1)\n",
        "    M_d = train_data_tensor[:, training_indices_of_class_k]\n",
        "\n",
        "    # p(m = 0 | k) =>  (observations == 0) / (total observations of class k)\n",
        "    p_m_0_given_k[k, :] = (M_d == 0.).sum(dim=1).div(M_d.shape[1])\n",
        "\n",
        "  # calculate complement => p(m = 1 | k)\n",
        "  p_m_1_given_k = p_m_1_given_k - p_m_0_given_k\n",
        "\n",
        "  return [p_m_0_given_k, p_m_1_given_k], p_t_tensor\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "#(train_data_tensor, labels_training) = load_dataset()\n",
        "#print(\"train dimensions \", train_data_tensor.shape)\n",
        "#print(\"train labels \", len(labels_training))\n",
        "\n",
        "#train model by calculating the prior probabilities\n",
        "(p_m_pix_val_given_k, p_t_tensor) = train_model(train_data_tensor, labels_training)\n",
        "print(f\"p_m_pix_val_given_k[0] size {p_m_pix_val_given_k[0].shape}\")\n",
        "print(f\"p_m_pix_val_given_k[1] size {p_m_pix_val_given_k[1].shape}\")\n",
        "print(f\"p_t_tensor \\n\\tclasses: {p_t_tensor.shape}.\\n\\tValues: {p_t_tensor}\")\n",
        "\n",
        "\n",
        "(predicted_label, scores_classes) = test_model(train_data_tensor[:, 500], p_m_pix_val_given_k, p_t_tensor)\n",
        "print(\"predicted_label \", predicted_label)\n",
        "print(\"real label \", labels_training[500])\n",
        "acc = test_model_batch(train_data_tensor, labels_training, p_m_pix_val_given_k, p_t_tensor)\n",
        "print(\"Model accuracy \", acc)\n",
        "    \n"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "FRo23D7FTRaO",
        "outputId": "b988c33e-1099-4f17-bff8-caa88906fb4d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "TP2_BayesianModel_MNIST_EVG.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}