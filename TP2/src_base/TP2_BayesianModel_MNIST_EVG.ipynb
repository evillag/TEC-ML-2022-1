{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/evillag/TEC-ML-2022-1/blob/main/TP2/src_base/TP2_BayesianModel_MNIST_EVG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "fV91T7yxTRaL"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from PIL import Image\n",
        "import torchvision.transforms.functional as TF\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!wget https://github.com/evillag/TEC-ML-2022-1/raw/main/TP2/src_base/mnist_dataset.zip\n",
        "!unzip /content/mnist_dataset.zip"
      ],
      "metadata": {
        "id": "CD_niHaQTuJL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "vXz83R23TRaM",
        "outputId": "c1ab807f-1ee0-450d-ceac-37f58727b72c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train dimensions  torch.Size([784, 600])\n",
            "train labels  600\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "\n",
        "def binarize_image(image_tensor):\n",
        "    image_tensor[image_tensor > 0.5] = 1\n",
        "    image_tensor[image_tensor <= 0.5] = 0\n",
        "    return image_tensor\n",
        "\n",
        "def load_dataset(path = \"mnist_dataset/train\"):\n",
        "    #Open up the dataset\n",
        "    dataset =  torchvision.datasets.ImageFolder(path)   \n",
        "    #print(dataset)\n",
        "    list_images = dataset.imgs\n",
        "    #print(list_images)\n",
        "    train_data_tensor  = None    \n",
        "    labels_training = []\n",
        "    first_tensor = True\n",
        "    #list_images_training =  set(data_labeled.train_ds.x.items)\n",
        "    #print(list_images)\n",
        "    for i in range(0, len(list_images)):\n",
        "        pair_path_label = list_images[i]        \n",
        "        image = Image.open(pair_path_label[0]) \n",
        "        x_tensor = TF.to_tensor(image).squeeze()\n",
        "        x_tensor_bin = binarize_image(x_tensor)\n",
        "\n",
        "        x_tensor_bin_plain = x_tensor_bin.view(x_tensor_bin.shape[0] * x_tensor_bin.shape[1], -1)        \n",
        "        #print(\"tensor \", x_tensor.shape)\n",
        "        #test dataset case        \n",
        "        #if(\"train\" in pair_path_label[0]):\n",
        "        labels_training += [pair_path_label[1]]\n",
        "        # print(pair_path_label)\n",
        "        if(first_tensor):\n",
        "            plt.figure()\n",
        "            plt.imshow(x_tensor_bin)\n",
        "            first_tensor = False\n",
        "            train_data_tensor = x_tensor_bin_plain\n",
        "        else:\n",
        "            train_data_tensor = torch.cat((train_data_tensor, x_tensor_bin_plain), 1)    \n",
        "    return (train_data_tensor, torch.tensor(labels_training))       \n",
        "\n",
        "\n",
        "(train_data_tensor, labels_training) = load_dataset(path = \"/content/mnist_dataset/train\")\n",
        "print(\"train dimensions \", train_data_tensor.shape)\n",
        "print(\"train labels \", len(labels_training))        \n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 1.0000e+00,  1.0000e+00,  1.0000e+00,  ...,  1.0000e+00,\n",
            "          1.0000e+00,  1.0000e+00],\n",
            "        [-8.6552e+14,  1.0000e+00,  7.4420e+36,  ...,  1.0000e+00,\n",
            "          1.0000e+00,  4.7395e+22],\n",
            "        [-1.2631e+29,  1.0000e+00,  1.2047e+00,  ...,  1.0000e+00,\n",
            "          1.0000e+00,  1.4407e+20],\n",
            "        ...,\n",
            "        [ 1.0000e+00,  1.0000e+00,  1.0000e+00,  ...,  1.0000e+00,\n",
            "         -2.1519e+31,  1.0000e+00],\n",
            "        [ 1.0000e+00,  1.0000e+00,  1.0000e+00,  ...,  1.0000e+00,\n",
            "          1.0000e+00,  1.0000e+00],\n",
            "        [-2.0095e+29,  1.0000e+00, -6.2995e+24,  ...,  1.0000e+00,\n",
            "         -5.3635e+13, -1.3232e+07]])\n",
            "p_m_pix_val_given_k[0] size torch.Size([10, 784])\n",
            "p_m_pix_val_given_k[1] size torch.Size([10, 784])\n",
            "p_t_tensor \n",
            "\tclasses: torch.Size([10]).\n",
            "\tValues: tensor([0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
            "        0.1000])\n"
          ]
        }
      ],
      "source": [
        "def test_model(input_torch, p_m_pix_val_given_k, p_t_tensor, num_classes = 10):\n",
        "    #assumes that the input comes in a row\n",
        "    #TODO IMPLEMENT\n",
        "    #return (predicted_label, scores_classes)\n",
        "    pass\n",
        "\n",
        "def test_model_batch(test_set, labels, p_m_pix_val_given_k, p_t_tensor):\n",
        "    return 0.0\n",
        "\n",
        "\n",
        "def train_model(train_data_tensor, labels_training, num_classes = 10):\n",
        "  p_m_0_given_k = torch.zeros(num_classes, train_data_tensor.shape[0])\n",
        "  \n",
        "  _, counts = torch.unique(labels_training, return_counts=True)\n",
        "  p_t_tensor = counts / len(labels_training)\n",
        "\n",
        "  for k in range(num_classes):\n",
        "    # Calculate p(train_data_tensor | k_i = t_i)\n",
        "\n",
        "  # calculate complement\n",
        "  p_m_1_given_k = torch.ones(num_classes, \n",
        "                             train_data_tensor.shape[0]) - p_m_0_given_k\n",
        "  print(p_m_1_given_k-p_m_0_given_k)\n",
        "  return [p_m_0_given_k, p_m_1_given_k], p_t_tensor\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "#(train_data_tensor, labels_training) = load_dataset()\n",
        "#print(\"train dimensions \", train_data_tensor.shape)\n",
        "#print(\"train labels \", len(labels_training))\n",
        "\n",
        "#train model by calculating the prior probabilities\n",
        "(p_m_pix_val_given_k, p_t_tensor) = train_model(train_data_tensor, labels_training)\n",
        "print(f\"p_m_pix_val_given_k[0] size {p_m_pix_val_given_k[0].shape}\")\n",
        "print(f\"p_m_pix_val_given_k[1] size {p_m_pix_val_given_k[1].shape}\")\n",
        "print(f\"p_t_tensor \\n\\tclasses: {p_t_tensor.shape}.\\n\\tValues: {p_t_tensor}\")\n",
        "\n",
        "\n",
        "# (predicted_label, scores_classes) = test_model(train_data_tensor[:, 500], p_m_pix_val_given_k, p_t_tensor)\n",
        "# print(\"predicted_label \", predicted_label)\n",
        "# print(\"real label \", labels_training[500])\n",
        "# acc = test_model_batch(train_data_tensor, labels_training, p_m_pix_val_given_k, p_t_tensor)\n",
        "# print(\"Model accuracy \", acc)\n",
        "    \n"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "FRo23D7FTRaO",
        "outputId": "5294a993-ec06-4764-afe7-75bcf3170ee0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels_training"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KeAut_SsZEMz",
        "outputId": "08892727-62c7-4fe9-dbd6-1c4baed642fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2,\n",
              "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
              "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
              "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4,\n",
              "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
              "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
              "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6,\n",
              "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
              "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
              "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
              "        7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
              "        7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8,\n",
              "        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
              "        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
              "        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
              "        9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
              "        9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p_m_pix_val_given_k[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eym5knrnZCMZ",
        "outputId": "8c2426f1-20e8-4d45-eee6-ef277746e92e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_data_tensor[1:200,0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FyGXBrpCYxfH",
        "outputId": "623e7752-89b2-47b2-ac56-0841e8555fae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0.])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "TP2_BayesianModel_MNIST_EVG.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}