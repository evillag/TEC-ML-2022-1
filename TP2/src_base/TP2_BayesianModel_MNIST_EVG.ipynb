{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/evillag/TEC-ML-2022-1/blob/main/TP2/src_base/TP2_BayesianModel_MNIST_EVG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "fV91T7yxTRaL"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from PIL import Image\n",
        "import torchvision.transforms.functional as TF\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!wget https://github.com/evillag/TEC-ML-2022-1/raw/main/TP2/src_base/mnist_dataset.zip\n",
        "!unzip /content/mnist_dataset.zip"
      ],
      "metadata": {
        "id": "CD_niHaQTuJL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "vXz83R23TRaM",
        "outputId": "f5f8dbc3-131c-422c-c711-c8e494b27f25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train dimensions  torch.Size([784, 600])\n",
            "train labels  600\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "\n",
        "def binarize_image(image_tensor):\n",
        "    image_tensor[image_tensor > 0.5] = 1\n",
        "    image_tensor[image_tensor <= 0.5] = 0\n",
        "    return image_tensor\n",
        "\n",
        "def load_dataset(path = \"mnist_dataset/train\"):\n",
        "    #Open up the dataset\n",
        "    dataset =  torchvision.datasets.ImageFolder(path)   \n",
        "    #print(dataset)\n",
        "    list_images = dataset.imgs\n",
        "    #print(list_images)\n",
        "    train_data_tensor  = None    \n",
        "    labels_training = []\n",
        "    first_tensor = True\n",
        "    #list_images_training =  set(data_labeled.train_ds.x.items)\n",
        "    #print(list_images)\n",
        "    for i in range(0, len(list_images)):\n",
        "        pair_path_label = list_images[i]        \n",
        "        image = Image.open(pair_path_label[0]) \n",
        "        x_tensor = TF.to_tensor(image).squeeze()\n",
        "        x_tensor_bin = binarize_image(x_tensor)\n",
        "\n",
        "        x_tensor_bin_plain = x_tensor_bin.view(x_tensor_bin.shape[0] * x_tensor_bin.shape[1], -1)        \n",
        "        #print(\"tensor \", x_tensor.shape)\n",
        "        #test dataset case        \n",
        "        #if(\"train\" in pair_path_label[0]):\n",
        "        labels_training += [pair_path_label[1]]\n",
        "        # print(pair_path_label)\n",
        "        if(first_tensor):\n",
        "            plt.figure()\n",
        "            plt.imshow(x_tensor_bin)\n",
        "            first_tensor = False\n",
        "            train_data_tensor = x_tensor_bin_plain\n",
        "        else:\n",
        "            train_data_tensor = torch.cat((train_data_tensor, x_tensor_bin_plain), 1)    \n",
        "    return (train_data_tensor, torch.tensor(labels_training))       \n",
        "\n",
        "\n",
        "(train_data_tensor, labels_training) = load_dataset(path = \"/content/mnist_dataset/train\")\n",
        "print(\"train dimensions \", train_data_tensor.shape)\n",
        "print(\"train labels \", len(labels_training))        \n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p_m_0_given_k shape torch.Size([10, 784])\n",
            "Quick sample of a priori probabilities\n",
            "tensor([1.0000, 0.9833, 0.9000, 0.8167, 0.7500, 0.6167, 0.5167, 0.5000, 0.5000,\n",
            "        0.4833, 0.5167, 0.4833, 0.3833, 0.4000, 0.6000, 0.6667, 0.7167, 0.8167,\n",
            "        0.9000, 0.9500, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000, 0.9833, 0.9500, 0.8833, 0.8333, 0.7833, 0.6667, 0.6333, 0.6333,\n",
            "        0.6667, 0.6500, 0.6333, 0.6167, 0.5000, 0.4333, 0.6000, 0.6833, 0.7167,\n",
            "        0.8167, 0.8833, 0.9333, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000, 1.0000, 0.9833, 0.9333, 0.9000, 0.8667, 0.8667, 0.8333, 0.8000,\n",
            "        0.7833, 0.8167, 0.7833, 0.7833, 0.7167, 0.5833, 0.5333, 0.5667, 0.6500,\n",
            "        0.7167, 0.8000, 0.9000, 0.9500, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000, 1.0000, 1.0000, 1.0000, 0.9667, 0.9333, 0.9500, 0.8833, 0.8833,\n",
            "        0.9000, 0.8833, 0.9333, 0.9000, 0.8500, 0.7000, 0.5833, 0.5333, 0.6000,\n",
            "        0.6167])\n",
            "tensor([0.0000, 0.0167, 0.1000, 0.1833, 0.2500, 0.3833, 0.4833, 0.5000, 0.5000,\n",
            "        0.5167, 0.4833, 0.5167, 0.6167, 0.6000, 0.4000, 0.3333, 0.2833, 0.1833,\n",
            "        0.1000, 0.0500, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0167, 0.0500, 0.1167, 0.1667, 0.2167, 0.3333, 0.3667, 0.3667,\n",
            "        0.3333, 0.3500, 0.3667, 0.3833, 0.5000, 0.5667, 0.4000, 0.3167, 0.2833,\n",
            "        0.1833, 0.1167, 0.0667, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0167, 0.0667, 0.1000, 0.1333, 0.1333, 0.1667, 0.2000,\n",
            "        0.2167, 0.1833, 0.2167, 0.2167, 0.2833, 0.4167, 0.4667, 0.4333, 0.3500,\n",
            "        0.2833, 0.2000, 0.1000, 0.0500, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0333, 0.0667, 0.0500, 0.1167, 0.1167,\n",
            "        0.1000, 0.1167, 0.0667, 0.1000, 0.1500, 0.3000, 0.4167, 0.4667, 0.4000,\n",
            "        0.3833])\n",
            "p_m_pix_val_given_k[0] size torch.Size([10, 784])\n",
            "p_m_pix_val_given_k[1] size torch.Size([10, 784])\n",
            "p_t_tensor \n",
            "\tclasses: torch.Size([10]).\n",
            "\tValues: tensor([0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
            "        0.1000])\n"
          ]
        }
      ],
      "source": [
        "def test_model(input_torch, p_m_pix_val_given_k, p_t_tensor, num_classes = 10):\n",
        "    #assumes that the input comes in a row\n",
        "    #TODO IMPLEMENT\n",
        "    #return (predicted_label, scores_classes)\n",
        "    pass\n",
        "\n",
        "def test_model_batch(test_set, labels, p_m_pix_val_given_k, p_t_tensor):\n",
        "    return 0.0\n",
        "\n",
        "\n",
        "def train_model(train_data_tensor, labels_training, num_classes = 10):\n",
        "  p_m_0_given_k = torch.zeros(num_classes, train_data_tensor.shape[0])\n",
        "  p_m_1_given_k = torch.ones(num_classes, train_data_tensor.shape[0])\n",
        "  \n",
        "  print(f'p_m_0_given_k shape {p_m_0_given_k.shape}')\n",
        "  \n",
        "  _, counts = torch.unique(labels_training, return_counts=True)\n",
        "  p_t_tensor = counts / len(labels_training)\n",
        "\n",
        "  for k in range(num_classes):\n",
        "    training_indices_of_class_k = (labels_training == k).nonzero().squeeze(1)\n",
        "    m = train_data_tensor[:, training_indices_of_class_k]\n",
        "\n",
        "    # p(m = 0 | k) =>  (observations == 0) / (total observations of class k)\n",
        "    p_m_0_given_k[k, :] = (m == 0.).sum(dim=1).div(m.shape[1])\n",
        "\n",
        "  # calculate complement => p(m = 1 | k)\n",
        "  p_m_1_given_k = p_m_1_given_k - p_m_0_given_k\n",
        "\n",
        "  return [p_m_0_given_k, p_m_1_given_k], p_t_tensor\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "#(train_data_tensor, labels_training) = load_dataset()\n",
        "#print(\"train dimensions \", train_data_tensor.shape)\n",
        "#print(\"train labels \", len(labels_training))\n",
        "\n",
        "#train model by calculating the prior probabilities\n",
        "(p_m_pix_val_given_k, p_t_tensor) = train_model(train_data_tensor, labels_training)\n",
        "print(f\"p_m_pix_val_given_k[0] size {p_m_pix_val_given_k[0].shape}\")\n",
        "print(f\"p_m_pix_val_given_k[1] size {p_m_pix_val_given_k[1].shape}\")\n",
        "print(f\"p_t_tensor \\n\\tclasses: {p_t_tensor.shape}.\\n\\tValues: {p_t_tensor}\")\n",
        "\n",
        "\n",
        "# (predicted_label, scores_classes) = test_model(train_data_tensor[:, 500], p_m_pix_val_given_k, p_t_tensor)\n",
        "# print(\"predicted_label \", predicted_label)\n",
        "# print(\"real label \", labels_training[500])\n",
        "# acc = test_model_batch(train_data_tensor, labels_training, p_m_pix_val_given_k, p_t_tensor)\n",
        "# print(\"Model accuracy \", acc)\n",
        "    \n"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "FRo23D7FTRaO",
        "outputId": "4b5290d0-a44d-4847-8dfc-67bdbca80c3f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filtrado = (labels_training == 0).nonzero()\n",
        "filtrado.squeeze(1).shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KeAut_SsZEMz",
        "outputId": "e74ed4cc-4408-43ed-9034-34a6d2f6da45"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([60])"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_clase_k = train_data_tensor[:,filtrado]\n",
        "print(f'shape filtrado {tensor_clase_k.shape}')\n",
        "\n",
        "p_m_0_given_k = torch.zeros(10, train_data_tensor.shape[0])\n",
        "print(f'p_m_0_given_k shape {p_m_0_given_k.shape}')\n",
        "p_m_0_given_k[0,:] = (tensor_clase_k == 0.).sum(dim=1).div(tensor_clase_k.shape[1])\n",
        "p_m_0_given_k[0,:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FyGXBrpCYxfH",
        "outputId": "88a6d61e-22ea-4f74-8dae-ddadc8fc0b5a"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape filtrado torch.Size([784, 60])\n",
            "p_m_0_given_k shape torch.Size([10, 784])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
              "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
              "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
              "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
              "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
              "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
              "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
              "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
              "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
              "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
              "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9833, 0.9833,\n",
              "        0.9833, 0.9500, 0.9833, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
              "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
              "        1.0000, 1.0000, 1.0000, 1.0000, 0.9833, 0.9833, 0.9667, 0.9333, 0.8167,\n",
              "        0.6667, 0.6833, 0.6333, 0.6333, 0.8167, 0.9000, 0.9500, 0.9833, 0.9833,\n",
              "        0.9833, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
              "        1.0000, 1.0000, 1.0000, 1.0000, 0.9833, 0.9500, 0.8833, 0.8000, 0.7167,\n",
              "        0.5167, 0.4333, 0.3833, 0.3500, 0.4167, 0.5833, 0.7333, 0.8167, 0.9167,\n",
              "        0.9833, 0.9833, 0.9833, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
              "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9333, 0.8333, 0.6833, 0.5833,\n",
              "        0.4667, 0.4000, 0.3000, 0.3000, 0.2833, 0.3000, 0.3667, 0.5333, 0.6333,\n",
              "        0.6833, 0.8500, 0.9333, 0.9833, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
              "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.8667, 0.7167, 0.6167,\n",
              "        0.4333, 0.3333, 0.3167, 0.2333, 0.2500, 0.2500, 0.3167, 0.2667, 0.4000,\n",
              "        0.4667, 0.6333, 0.7000, 0.8667, 0.9667, 1.0000, 1.0000, 1.0000, 1.0000,\n",
              "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9833, 0.9000, 0.7333, 0.6500,\n",
              "        0.5500, 0.4167, 0.3667, 0.2500, 0.3500, 0.4333, 0.4000, 0.3833, 0.3333,\n",
              "        0.3500, 0.3667, 0.5333, 0.6833, 0.8167, 0.9500, 1.0000, 1.0000, 1.0000,\n",
              "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9000, 0.8000, 0.7000,\n",
              "        0.5833, 0.4333, 0.4000, 0.3167, 0.4500, 0.5500, 0.5833, 0.6833, 0.6167,\n",
              "        0.5167, 0.4167, 0.4667, 0.5000, 0.6500, 0.8000, 0.9333, 1.0000, 1.0000,\n",
              "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9833, 0.8500, 0.7167,\n",
              "        0.6667, 0.4333, 0.3167, 0.3667, 0.4167, 0.5833, 0.6667, 0.8000, 0.8167,\n",
              "        0.7500, 0.5833, 0.5167, 0.4167, 0.4500, 0.5000, 0.6833, 0.9167, 1.0000,\n",
              "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9333, 0.8167,\n",
              "        0.6833, 0.5167, 0.3167, 0.3167, 0.4000, 0.5667, 0.7500, 0.8333, 0.8833,\n",
              "        0.9000, 0.8000, 0.7333, 0.5333, 0.3833, 0.3833, 0.4500, 0.6500, 0.9000,\n",
              "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.8833,\n",
              "        0.7333, 0.6000, 0.3500, 0.2833, 0.3167, 0.5167, 0.7167, 0.8333, 0.9000,\n",
              "        0.9500, 0.9833, 0.9167, 0.8167, 0.6167, 0.4333, 0.3833, 0.4000, 0.6167,\n",
              "        0.8667, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
              "        0.8667, 0.6833, 0.4833, 0.2500, 0.3000, 0.5000, 0.7000, 0.8167, 0.9500,\n",
              "        0.9833, 0.9833, 1.0000, 0.9167, 0.8667, 0.5833, 0.4667, 0.2833, 0.4333,\n",
              "        0.6000, 0.8833, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
              "        0.9833, 0.8000, 0.6000, 0.3667, 0.2167, 0.3667, 0.6333, 0.8000, 0.9000,\n",
              "        0.9833, 1.0000, 1.0000, 1.0000, 0.9500, 0.8667, 0.5667, 0.4333, 0.3167,\n",
              "        0.4500, 0.6333, 0.8833, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
              "        1.0000, 0.9667, 0.7167, 0.5167, 0.2500, 0.2667, 0.5000, 0.7000, 0.8500,\n",
              "        0.9667, 1.0000, 1.0000, 1.0000, 1.0000, 0.9500, 0.7833, 0.5333, 0.3500,\n",
              "        0.3333, 0.4833, 0.6833, 0.9000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
              "        1.0000, 1.0000, 0.9500, 0.6667, 0.4333, 0.2500, 0.2833, 0.6167, 0.7833,\n",
              "        0.9000, 0.9500, 1.0000, 1.0000, 0.9833, 0.9500, 0.8667, 0.6333, 0.4667,\n",
              "        0.3167, 0.3833, 0.5333, 0.7333, 0.9500, 1.0000, 1.0000, 1.0000, 1.0000,\n",
              "        1.0000, 1.0000, 1.0000, 0.9167, 0.6667, 0.3833, 0.2833, 0.3167, 0.6000,\n",
              "        0.8667, 0.8833, 0.9333, 0.9833, 0.9833, 0.9667, 0.8833, 0.6833, 0.5167,\n",
              "        0.4333, 0.3333, 0.5000, 0.6500, 0.7833, 0.9500, 1.0000, 1.0000, 1.0000,\n",
              "        1.0000, 1.0000, 1.0000, 1.0000, 0.9167, 0.6167, 0.4167, 0.3333, 0.3333,\n",
              "        0.6000, 0.7667, 0.8333, 0.8833, 0.8833, 0.8667, 0.7833, 0.6333, 0.5167,\n",
              "        0.4167, 0.3667, 0.4500, 0.5833, 0.7667, 0.8833, 1.0000, 1.0000, 1.0000,\n",
              "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9000, 0.6333, 0.4500, 0.3000,\n",
              "        0.3500, 0.4000, 0.6000, 0.7000, 0.7667, 0.7833, 0.6500, 0.5167, 0.4833,\n",
              "        0.3833, 0.3833, 0.3833, 0.5000, 0.6833, 0.8167, 0.9333, 1.0000, 1.0000,\n",
              "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9167, 0.7667, 0.5000,\n",
              "        0.3167, 0.3333, 0.2500, 0.3333, 0.4500, 0.5333, 0.4833, 0.4500, 0.3667,\n",
              "        0.3833, 0.3167, 0.3667, 0.5333, 0.6333, 0.8167, 0.9167, 1.0000, 1.0000,\n",
              "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9833, 0.8333,\n",
              "        0.6500, 0.5167, 0.3000, 0.1833, 0.1167, 0.1500, 0.3000, 0.2333, 0.2167,\n",
              "        0.2833, 0.2833, 0.4167, 0.5000, 0.6333, 0.8167, 0.9500, 0.9833, 1.0000,\n",
              "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
              "        0.9500, 0.8000, 0.7167, 0.5500, 0.2500, 0.2167, 0.1333, 0.1333, 0.2667,\n",
              "        0.3167, 0.4000, 0.4333, 0.5833, 0.7000, 0.8333, 0.9667, 1.0000, 1.0000,\n",
              "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
              "        1.0000, 1.0000, 0.9500, 0.8833, 0.8167, 0.7833, 0.6667, 0.5000, 0.4500,\n",
              "        0.4333, 0.5000, 0.6167, 0.7333, 0.8500, 0.9667, 1.0000, 1.0000, 1.0000,\n",
              "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
              "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9833, 0.9667,\n",
              "        0.9000, 0.8833, 0.9000, 0.9333, 0.9833, 1.0000, 1.0000, 1.0000, 1.0000,\n",
              "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
              "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
              "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
              "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
              "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
              "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
              "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
              "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
              "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
              "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
              "        1.0000])"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "YCoa_RVEMAKb"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "TP2_BayesianModel_MNIST_EVG.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}